{"pageProps":{"post":{"attributes":{"title":"Special tags we use and why","description":"Special tags we use and why"},"html":"<h2 id=\"special-tags-we-use-and-why\">Special tags we use and why</h2>\n<p>Some tags have been introduced to help control tests and scope. We use them to orchestrate test runs both locally and as part of the CI and deployment pipelines.</p>\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n\n<h4 id=\"fixturesomething-something\"><strong>@fixture.&lt;something-something&gt;</strong></h4>\n<p>We use these for pre-conditions, setup and tear-down before and after test execution. </p>\n<pre><code class=\"hljs language-gherkin\"><span class=\"hljs-meta\">@fixture.role.validate</span>\n<span class=\"hljs-meta\">@fixture.s3.create_bucket</span>\n<span class=\"hljs-meta\">@fixture.s3.upload.test_data.vision.classification</span>\n<span class=\"hljs-keyword\">Feature</span>: Model evaluation can be triggered via an API\n</code></pre>\n<pre><code class=\"hljs language-gherkin\"><span class=\"hljs-meta\">@fixture.launch.tabular.classification.app</span>\n<span class=\"hljs-keyword\">Feature</span>: As a data scientist, when evaluating an inference unit, then I want the evaluation report to consist\n</code></pre>\n<pre><code class=\"hljs language-gherkin\"><span class=\"hljs-meta\">@fixture.launch.image.binary.classification.app</span>\n<span class=\"hljs-keyword\">Feature</span>: It must be possible to assess that an image binary classification inference unit behaves as intended\n</code></pre>\n<pre><code class=\"hljs language-gherkin\"><span class=\"hljs-meta\">@fixture.launch.vision.classification.app</span>\n<span class=\"hljs-meta\">@fixture.vision.classification.inference</span>\n<span class=\"hljs-keyword\">Feature</span>: Evaluation plan definition\n</code></pre>\n<p>In this session we will not deep dive into how these work. Furthermore, Behave has specific implementation details as do other test runners.</p>\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n\n<h4 id=\"offline\"><strong>@offline</strong></h4>\n<p>Just running tests. This tag signifies a test can run offlineâ€”that is, locally.</p>\n<pre><code class=\"hljs language-gherkin\"><span class=\"hljs-meta\">@offline</span>\n...\n<span class=\"hljs-keyword\">Feature</span>: It must be possible to assess that a tabular regression inference unit behaves as intended\n</code></pre>\n<p>To run all offline tests:</p>\n<pre><code class=\"hljs language-bash\">behave --tags <span class=\"hljs-string\">&#x27;@offline&#x27;</span> iu_validation/features\n</code></pre>\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n\n<h4 id=\"container\"><strong>@container</strong></h4>\n<p>For tests that depend on a Docker container.</p>\n<pre><code class=\"hljs language-gherkin\"><span class=\"hljs-meta\">@container</span>\n<span class=\"hljs-keyword\">Scenario</span>: Perform end-to-end evaluation via the docker container (success)\n    <span class=\"hljs-keyword\">Given</span> a test dataset for image binary classification\n    <span class=\"hljs-keyword\">And</span> an evaluation plan file for image binary classification with no evaluation tasks and no report specification\n    <span class=\"hljs-keyword\">And</span> with local report file location\n    <span class=\"hljs-keyword\">When</span> we invoke the inference unit evaluation container with local inference\n    <span class=\"hljs-keyword\">Then</span> the application returns a successful exit code\n</code></pre>\n<p>To run all container-based tests:</p>\n<pre><code class=\"hljs language-bash\">behave --tags <span class=\"hljs-string\">&#x27;@container&#x27;</span> iu_validation/features\n</code></pre>\n<p>Or leave them out:</p>\n<pre><code class=\"hljs language-bash\">behave --tags <span class=\"hljs-string\">&#x27;~@container&#x27;</span> iu_validation/features\n</code></pre>\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n\n<h4 id=\"inprogress\"><strong>@InProgress</strong></h4>\n<p>Flag for us to indicate a scenario is not yet complete. We can run tests with or without these scenarios.</p>\n<p>Here is one that is commented out, because there is no feature flag for it yet:</p>\n<pre><code class=\"hljs language-gherkin\"><span class=\"hljs-comment\">#  @PV @InProgress</span>\n<span class=\"hljs-comment\">#  Scenario: Perform inference unit evaluation with a multiple image datapoint request to the inference unit</span>\n<span class=\"hljs-comment\">#    Given an inference unit utilizing multiple images for predictions</span>\n<span class=\"hljs-comment\">#    And a dataset in the coco dataset format supporting multiple images for each datapoint</span>\n<span class=\"hljs-comment\">#    When we run inference unit evaluation</span>\n<span class=\"hljs-comment\">#    Then we parse the responses from the inference unit as a single prediction</span>\n<span class=\"hljs-comment\">#    Then metrics are calculated correctly</span>\n</code></pre>\n<p>To run without the tests for features/scenarios marked as <em>in progress</em>:</p>\n<pre><code class=\"hljs language-bash\">behave --tags <span class=\"hljs-string\">&#x27;~@InProgress&#x27;</span> iu_validation/features\n</code></pre>\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n\n<h4 id=\"s3\"><strong>@s3</strong></h4>\n<h4 id=\"aws\"><strong>@aws</strong></h4>\n<h4 id=\"dynamodb\"><strong>@dynamodb</strong></h4>\n<br />\n\n<p>Identifies tests that have something to do with <em>s3</em>, <em>dynamodb</em> or <em>aws</em> in general and thus dependencies to AWS cloud at runtime.</p>\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />\n<br />","slug":"special-tags-we-use-and-why","title":"Special tags we use and why","section":"How We Have Done Things","icon":"info-circle","filePath":"/home/runner/work/lasselundstenjensen.github.io/lasselundstenjensen.github.io/lessons/01-how-we-have-done-things/C-special-tags-we-use-and-why.md","nextSlug":"/lessons/how-we-have-done-things/mocking","prevSlug":"/lessons/how-we-have-done-things/what-we-think-about-testing"}},"__N_SSG":true}